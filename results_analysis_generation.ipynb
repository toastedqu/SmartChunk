{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Analysis for Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 3 evaluation metrics, averaged across all queries for each dataset.\n",
    "- **BLEU**: lexical similarity between generated and actual answers.\n",
    "- **BERTScore**: semantic similarity between generated and actual answers.\n",
    "- **Cosine Similarity (QA)**: similarity based on query and answer embeddings from an embedding model pretrained on QA datasets.\n",
    "    - BERTScore focuses more on semantically similar sentences instead of the alignment between questions and answers. Hence, it's better to use an embedding model pretrained for the objective of QA alignment to calculate this similarity.\n",
    "\n",
    "Alternatively, we can prompt LLM to test the correctness of our generated answer, but that will be costly and requires permission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load(open('results/results_generation.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_results(results, metric):\n",
    "    for dataset, dataset_results in results.items():\n",
    "        print(dataset)\n",
    "        best = {}\n",
    "        for model, model_results in sorted(dataset_results.items(), key=lambda x: x[1][metric], reverse=True):\n",
    "            chunker = model.split('|')[0]\n",
    "            best[chunker] = max(best.get(chunker, 0), model_results[metric])\n",
    "        for best_chunker, best_score in best.items():\n",
    "            print(best_chunker, best_score)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditionalqa\n",
      "AbsoluteLangchainChunker 0.025614291872207838\n",
      "SingleLinkageChunker 0.024923561057551367\n",
      "PositionalChunker 0.024393325506382017\n",
      "LangchainChunker 0.02137819499443067\n",
      "DBSCANChunker 0.0211334618369416\n",
      "BaseChunker 0.01964963641011951\n",
      "\n",
      "cuad\n",
      "PositionalChunker 0.09709458461164729\n",
      "DBSCANChunker 0.09707640001750076\n",
      "SingleLinkageChunker 0.09689114850435061\n",
      "BaseChunker 0.09477256568052747\n",
      "LangchainChunker 0.09372428288341171\n",
      "AbsoluteLangchainChunker 0.06617159425354206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_results(results, 'bleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditionalqa\n",
      "LangchainChunker 0.4347497642040253\n",
      "AbsoluteLangchainChunker 0.43426079243421556\n",
      "DBSCANChunker 0.4327026492357254\n",
      "PositionalChunker 0.41655766814947126\n",
      "SingleLinkageChunker 0.41478910341858866\n",
      "BaseChunker 0.3912048231065273\n",
      "\n",
      "cuad\n",
      "PositionalChunker 0.6153298634290695\n",
      "DBSCANChunker 0.6126029688119888\n",
      "SingleLinkageChunker 0.6107689866423607\n",
      "LangchainChunker 0.6106900158524513\n",
      "BaseChunker 0.6092399621009826\n",
      "AbsoluteLangchainChunker 0.5903419572114944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_results(results, 'bertscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditionalqa\n",
      "LangchainChunker 0.35828339397907255\n",
      "PositionalChunker 0.3570630721747875\n",
      "DBSCANChunker 0.3567922805249691\n",
      "SingleLinkageChunker 0.35658444866538047\n",
      "AbsoluteLangchainChunker 0.3563793709874153\n",
      "BaseChunker 0.3546047221124172\n",
      "\n",
      "cuad\n",
      "LangchainChunker 0.8303691279888153\n",
      "AbsoluteLangchainChunker 0.8287693744897843\n",
      "DBSCANChunker 0.8283072090148926\n",
      "SingleLinkageChunker 0.8221230947971344\n",
      "PositionalChunker 0.8179567801952362\n",
      "BaseChunker 0.7740970557928085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_results(results, 'qa_cos_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
